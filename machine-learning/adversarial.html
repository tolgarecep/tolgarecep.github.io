<!DOCTYPE html><html><head>
    <meta charset="UTF-8"><title>tolga recep</title>
    <meta name="description">
    <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@300&display=swap" rel="stylesheet">
    <style type="text/css">
            .tab { margin-left: 40px; }
            body,td,th {
                font-family: Segoe, "Segoe UI", "DejaVu Sans", "Trebuchet MS", Verdana, sans-serif;
                /*font-family: 'Roboto Mono', monospace;
                font-weight: bold;
            */}
            a.credit:link {
                color: #000000;
                text-decoration: none;
            }
            a.credit:visited {
                text-decoration: none;
                color: #000000;
            }
            a.credit:hover {
                text-decoration: none;
                color: #FFFFFF;
                background-color: #000000;
            }
            a.credit:active {
                text-decoration: none;
                color: #000000;
            }
            body {
                margin-top: 33px;
            }
                .tmblr-iframe-compact .tmblr-iframe--unified-controls {display: none;
            }
            .list {
            width:1120px;
            height:450px;
            position:fixed;
            margin-left:-560px;
            margin-top:-280px;
            top:50%;
            left:50%;
            }
            img {
            width:750px;
            height:400px;
            }
        </style>
    </head>
    <body>
    <!--TITLE HERE-->
    <strong>wag the dog</strong><br>
    <!--VERSION-->
    <i>writer's cut</i><br>
<p>
<font size="-1">
<!--ESSAY-->
<p>"These results suggest that classifiers based on modern machine learning techniques, even those
    that obtain excellent performance on the test set, are not learning the true underlying concepts that
    determine the correct output label. Instead, these algorithms have built a Potemkin village that works
    well on naturally occuring data, but is exposed as a fake when one visits points in space that do not
    have high probability in the data distribution."
<br>
Goodfellow, EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES</p>
<p>That is the core premise behind the concept of "attacking" machine learning models. Modeling is not hard-coding domain field's principles, or principles of
    the visual world, and so on, but to justify the data and then mitigate this over-care for the noisy subset of real world and create an extrapolating function.
</p>
<h3>The Nature of Data & Linear Transformation</h3>
<p>Precision of the way we generally represent real world inside our computers *and* the sensitivity of linear transformation to small perturbations create this attackable
    nature of classifiers. Simply put, since an image is not very precise (when representing the real world correpondence), computing it or some image very similar to it should
    give the same result. 
</p>
<p>Definiton of the attacking objective is:
</p>
<p>x is very similar to x_adv AND y dramatically changes</p>

<!--WRITTEN BY-->
<p><b>tolga recep u√ßar</b><br>
2022
</p>

</font>
</p>
</body>
</html>