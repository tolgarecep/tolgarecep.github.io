<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8">
  <title>tolga recep</title>
  <style type="text/css">
    a {
      color: blue;
      text-decoration: none;
    }

    p {
      width: 700px;
    }
  </style>
</head>

<body>
  <table width="100%" border="0" cellspacing="0" cellpadding="0">
    <tbody>
      <tr valign="top">
        <td colspan="2">
          <h1>Tolga Recep Uçar</h1>
        </td>
      </tr>
      <tr valign="top">
        <td width="350">
          <div align="left">
            Data Engineer @ Turkish Airlines Technic<br>
            BSc Mathematics @ Yıldız Technical University<br>
            tolgarecepucar (at) gmail (dot) com <br></div>
        </td>
        <td>
          <ul>
            <li><a href="cv.pdf" target="_blank">CV</a></li>
            <li><a href="https://github.com/tolgarecep" target="_blank">Github</a></li>
          </ul>
        </td>
      </tr>
    </tbody>
  </table>
  <hr>
  <h3>Research</h3>
  <h3><i>Transformer-based Variational Autoencoders</i></h3>
  <p><b>TUBITAK granted research (2247-C.)</b>
    Supervised by Prof. Dr. Mehmet Fatih Amasyalı. We propose an alternative VAE architecture inspired by the inner workings of the ubiquitous Transformer. We also diagnose the condition of posterior collapse on the latent space and aggressively train the encoder to create an efficient model overcoming this. Finally the architecture is trained on a large Turkish corpora and tested on various tasks such as sentiment analysis and text classification. Publicly available <a
      href="https://github.com/tolgarecep/aggr-transformer-vae">here</a>.</p>
  <h3><i>Orthogonal embedding-based neural network for solving nonlinear differential equations</i></h3>
  <p><b>(Pre-submission.)</b> We propose a numerical algorithm based on neural networks for solving linear and nonlinear ordinary differential equa- tions. We combine the representational power of orthogonal space of Jacobi polynomials and multilayer perceptrons. Our method presents low-cost and highly accurate approximations with basic training. Some of the tinkering before the actual architecture was designed can be found <a href="https://github.com/tolgarecep/various">here</a>.</p>
  <h3>Proposals</h3>
  <i>
    <h3>Solving Abel type differential equations using multilayer perceptron
      <br> at
      <small>International Conference on Mathematical Analysis and Applications in Science and
        Engineering - ICMASC'24 <br>(Portugal, June 20th - 22nd 2024)
  </i></small></h3>
  <p><b>(Accepted for on-site oral presentation and print.)</b>
    <b>Abstract:</b>
    We propose machine learning as a
    new method for solving Abel type differential
    equations which is an important class of
    differential equations modeling magnetostatic
    problems and fluid dynamics. Our method does
    not rely on extensive formal numeric
    computing. It is a data-driven algorithm, hence
    a significant approach as data is more available
    each day. Our approximation function is a
    multilayer perceptron and we adjust parameters
    by backpropagation algorithm. We compare our
    results with some well-known approximate
    results. <br>
  </p>
  <h3>Professional work</h3>
  <p><b>Data Engineer: (Currently)</b> Integrating, consolidating and cleaning data and structuring it for analysis and
    modeling at Turkish
    Technic, the MRO of Turkish Airlines. Developing clustering, supervised and unsupervised learning solutions for
    component planning problems. <br><br>
    <b>(and I was a Freelance Python Tutor before this.)</b>
  </p>
  <h3>Film theory</h3>
  <a href="glazer23.html">Camera as Ideology in 'The Zone of Interest (2023, Glazer)'</a>
  <h3>Modernism</h3>
  <a href="ceylan23.html">Beyond the Psychology of 'About Dry Grasses (2023, Ceylan)'</a>
</body>

</html>
